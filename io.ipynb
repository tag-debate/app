{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_fW0stPY4vU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f6f474a-7287-47c7-8d5f-fabed5e83a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Análise das Representações da IA no Cinema"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados carregados com sucesso!\n",
            "Pré-processamento dos dados...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Dados Carregados"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   filme_id                  titulo   ano             genero  \\\n",
            "0         1  A Revolta das Máquinas  2023  Ficção Científica   \n",
            "1         2        O Código da Vida  2022              Drama   \n",
            "2         3      O Androide Perdido  2021  Ficção Científica   \n",
            "3         4      Ameaça Cibernética  2020           Suspense   \n",
            "4         5           O Sonho da IA  2019              Drama   \n",
            "\n",
            "                                             dialogo  bilheteria  \\\n",
            "0  “As máquinas estão se rebelando! Precisamos de...   120000000   \n",
            "1  “A inteligência artificial pode curar doenças,...    85000000   \n",
            "2  “Eu sou um androide, mas também tenho sentimen...    60000000   \n",
            "3  “O hacker invadiu o sistema e agora controla t...    95000000   \n",
            "4  “Eu criei uma IA que pode compor músicas incrí...    70000000   \n",
            "\n",
            "  avaliacao_critica  \n",
            "0             8.5 |  \n",
            "1             7.9 |  \n",
            "2             6.8 |  \n",
            "3             8.2 |  \n",
            "4             7.5 |  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40 entries, 0 to 39\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   filme_id           40 non-null     int64 \n",
            " 1   titulo             40 non-null     object\n",
            " 2   ano                40 non-null     int64 \n",
            " 3   genero             40 non-null     object\n",
            " 4   dialogo            40 non-null     object\n",
            " 5   bilheteria         40 non-null     int64 \n",
            " 6   avaliacao_critica  40 non-null     object\n",
            "dtypes: int64(3), object(4)\n",
            "memory usage: 2.3+ KB\n",
            "None\n",
            "        filme_id          ano    bilheteria\n",
            "count  40.000000    40.000000  4.000000e+01\n",
            "mean   20.500000  2003.500000  6.687500e+07\n",
            "std    11.690452    11.690452  2.217898e+07\n",
            "min     1.000000  1984.000000  2.500000e+07\n",
            "25%    10.750000  1993.750000  5.000000e+07\n",
            "50%    20.500000  2003.500000  6.500000e+07\n",
            "75%    30.250000  2013.250000  8.125000e+07\n",
            "max    40.000000  2023.000000  1.200000e+08\n",
            "Analisando sentimento...\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/distribuicao_sentimento.png\n",
            "Realizando modelagem de tópicos (LDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tópico: 0 \n",
            "Palavras: 0.215*\"ia\" + 0.112*\"futuro\" + 0.061*\"enigma\" + 0.061*\"androide\" + 0.061*\"perdido\" + 0.061*\"criação\" + 0.010*\"máquina\" + 0.010*\"vida\" + 0.010*\"máquinas\" + 0.010*\"artificial\"\n",
            "\n",
            "Tópico: 1 \n",
            "Palavras: 0.068*\"artificial\" + 0.068*\"digital\" + 0.068*\"cibernética\" + 0.068*\"inteligência\" + 0.068*\"ameaça\" + 0.068*\"cérebro\" + 0.068*\"legado\" + 0.068*\"turing\" + 0.012*\"ia\" + 0.012*\"futuro\"\n",
            "\n",
            "Tópico: 2 \n",
            "Palavras: 0.124*\"máquinas\" + 0.069*\"vida\" + 0.068*\"criação\" + 0.068*\"algoritmo\" + 0.068*\"limite\" + 0.068*\"revolta\" + 0.068*\"visão\" + 0.012*\"ia\" + 0.011*\"máquina\" + 0.011*\"artificial\"\n",
            "\n",
            "Tópico: 3 \n",
            "Palavras: 0.353*\"ia\" + 0.062*\"máquina\" + 0.023*\"potencial\" + 0.023*\"dilema\" + 0.023*\"propósito\" + 0.023*\"sonho\" + 0.023*\"coração\" + 0.023*\"amanhecer\" + 0.023*\"mistério\" + 0.023*\"despertar\"\n",
            "\n",
            "Tópico: 4 \n",
            "Palavras: 0.111*\"ia\" + 0.061*\"promessa\" + 0.061*\"robôs\" + 0.061*\"esperança\" + 0.061*\"rede\" + 0.061*\"consciência\" + 0.061*\"neural\" + 0.061*\"mundo\" + 0.061*\"artificial\" + 0.011*\"máquinas\"\n",
            "\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/topico_0.png\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/topico_1.png\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/topico_2.png\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/topico_3.png\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/topico_4.png\n",
            "Analisando correlações...\n",
            "\n",
            "Matriz de Correlação:\n",
            "             filme_id       ano  bilheteria  sentimento\n",
            "filme_id    1.000000 -1.000000   -0.525365         NaN\n",
            "ano        -1.000000  1.000000    0.525365         NaN\n",
            "bilheteria -0.525365  0.525365    1.000000         NaN\n",
            "sentimento       NaN       NaN         NaN         NaN\n",
            "Gráfico salvo: /content/drive/MyDrive/graficos/matriz_correlacao.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Conclusões Preliminares"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Este notebook realizou análises iniciais. Próximas etapas: refinamento do pré-processamento, análise de outras colunas, implementação da análise visual, e integração com outras técnicas (Scikit-learn, XGBoost, SHAP, etc.)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import spacy\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import LdaModel\n",
        "from IPython.display import display, Markdown  # Para exibir Markdown no Colab\n",
        "import os  # Para criar diretórios\n",
        "from google.colab import drive  # Importa a API do Google Drive\n",
        "\n",
        "# --- Configurações Iniciais ---\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Caminho base no Google Drive\n",
        "drive_base_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# 3. Criação do diretório para salvar os gráficos no Drive\n",
        "pasta_graficos = \"graficos\"\n",
        "drive_graficos_path = os.path.join(drive_base_path, pasta_graficos)\n",
        "if not os.path.exists(drive_graficos_path):\n",
        "    os.makedirs(drive_graficos_path)\n",
        "\n",
        "# 4. URL do dataset (Google Sheets)\n",
        "url_dataset = \"https://docs.google.com/spreadsheets/d/1xI-kcwIx0aFQAi5JxsjuAknPiBmLlCW0dzE3ag3s0Io/export?format=csv\"\n",
        "\n",
        "# --- Configurações de Estilo dos Gráficos ---\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.rcParams.update({\n",
        "    'figure.facecolor': 'black',\n",
        "    'axes.facecolor': 'black',\n",
        "    'axes.edgecolor': 'white',\n",
        "    'axes.labelcolor': 'cyan',\n",
        "    'xtick.color': 'white',\n",
        "    'ytick.color': 'white',\n",
        "    'text.color': 'white',\n",
        "    'grid.color': 'gray',\n",
        "    'grid.linestyle': '--',\n",
        "    'legend.facecolor': 'black',\n",
        "    'legend.edgecolor': 'white',\n",
        "    'figure.titlesize': 20,\n",
        "    'axes.titlesize': 16,\n",
        "    'axes.labelsize': 14,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'legend.fontsize': 12,\n",
        "})\n",
        "DEFAULT_PALETTE = \"viridis\"\n",
        "FIGSIZE = (12, 8)\n",
        "\n",
        "# --- Funções Auxiliares ---\n",
        "\n",
        "def create_figure():\n",
        "    \"\"\"Cria uma figura com as configurações padrão.\"\"\"\n",
        "    return plt.figure(figsize=FIGSIZE)\n",
        "\n",
        "def save_fig(fig, filename):\n",
        "    \"\"\"Salva a figura no Drive.\"\"\"\n",
        "    filepath = os.path.join(drive_graficos_path, filename)\n",
        "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Gráfico salvo: {filepath}\")\n",
        "    plt.close(fig)  # Importante para liberar memória\n",
        "\n",
        "# --- Funções de Análise ---\n",
        "\n",
        "def carregar_dados(url):\n",
        "    \"\"\"Carrega os dados do Google Sheets (CSV) em um DataFrame Pandas.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(url)\n",
        "        print(\"Dados carregados com sucesso!\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar os dados: {e}\")\n",
        "        return None\n",
        "\n",
        "def pre_processar_dados(df):\n",
        "    \"\"\"\n",
        "    Realiza o pré-processamento inicial dos dados (limpeza, tratamento de missings, etc.).\n",
        "    \"\"\"\n",
        "    print(\"Pré-processamento dos dados...\")\n",
        "    # Converte nomes de colunas para minúsculas e substitui espaços por _\n",
        "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
        "\n",
        "    # Exemplo de tratamento de valores ausentes (preencher com a média, se numérico)\n",
        "    for col in df.columns:\n",
        "        if df[col].isnull().any():\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                df[col] = df[col].fillna(df[col].mean())\n",
        "                print(f\"Valores ausentes na coluna '{col}' preenchidos com a média.\")\n",
        "            else:\n",
        "                # Se não for numérico, você pode preencher com a moda, um valor constante, ou dropar as linhas\n",
        "                df[col] = df[col].fillna(df[col].mode()[0])  # Ex: preencher com a moda\n",
        "                print(f\"Valores ausentes na coluna '{col}' preenchidos com a moda.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def analisar_sentimento(df, coluna_texto):\n",
        "    \"\"\"\n",
        "    Analisa o sentimento de uma coluna de texto do DataFrame.\n",
        "    Retorna o DataFrame com uma nova coluna 'sentimento'.\n",
        "    \"\"\"\n",
        "    print(\"Analisando sentimento...\")\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    def get_sentiment_score(text):\n",
        "        \"\"\"Calcula o score de sentimento composto (VADER).\"\"\"\n",
        "        if isinstance(text, str):\n",
        "            return sia.polarity_scores(text)['compound']\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    df['sentimento'] = df[coluna_texto].apply(get_sentiment_score)\n",
        "    return df\n",
        "\n",
        "def visualizar_distribuicao_sentimento(df, coluna_sentimento='sentimento'):\n",
        "    \"\"\"\n",
        "    Visualiza a distribuição dos scores de sentimento usando um histograma.\n",
        "    \"\"\"\n",
        "    fig = create_figure()\n",
        "    sns.histplot(data=df, x=coluna_sentimento, kde=True, color='cyan')  # Cor consistente\n",
        "    plt.title('Distribuição dos Scores de Sentimento')\n",
        "    plt.xlabel('Score de Sentimento (VADER)')\n",
        "    plt.ylabel('Frequência')\n",
        "    save_fig(fig, 'distribuicao_sentimento.png')\n",
        "\n",
        "\n",
        "\n",
        "def modelagem_de_topicos(df, coluna_texto, num_topicos=5):\n",
        "    \"\"\"\n",
        "    Realiza a modelagem de tópicos (LDA).\n",
        "    \"\"\"\n",
        "    print(\"Realizando modelagem de tópicos (LDA)...\")\n",
        "\n",
        "    try:\n",
        "        nlp = spacy.load(\"pt_core_news_sm\")\n",
        "    except:\n",
        "        print(\"Modelo 'pt_core_news_sm' não encontrado. Tentando baixar...\")\n",
        "        try:\n",
        "            spacy.cli.download(\"pt_core_news_sm\")\n",
        "            nlp = spacy.load(\"pt_core_news_sm\")\n",
        "        except:\n",
        "            print(\"Não foi possível baixar o modelo. Verifique sua conexão.\")\n",
        "            return None, None\n",
        "\n",
        "    def preprocessar_texto(texto):\n",
        "        if isinstance(texto, str):\n",
        "            doc = nlp(texto)\n",
        "            tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
        "            return tokens\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    textos_processados = df[coluna_texto].apply(preprocessar_texto)\n",
        "    id2word = corpora.Dictionary(textos_processados)\n",
        "    corpus = [id2word.doc2bow(texto) for texto in textos_processados]\n",
        "\n",
        "    lda_model = LdaModel(corpus=corpus,\n",
        "                         id2word=id2word,\n",
        "                         num_topics=num_topicos,\n",
        "                         random_state=42,\n",
        "                         passes=10)\n",
        "\n",
        "    for idx, topic in lda_model.print_topics(-1):\n",
        "        print(f\"Tópico: {idx} \\nPalavras: {topic}\\n\")\n",
        "\n",
        "    return lda_model, corpus\n",
        "\n",
        "\n",
        "\n",
        "def visualizar_topicos(lda_model, corpus, num_palavras=10):\n",
        "    \"\"\"\n",
        "    Visualiza os tópicos gerados pelo modelo LDA (gráfico de barras).\n",
        "    \"\"\"\n",
        "    topicos = lda_model.show_topics(num_topics=-1, num_words=num_palavras, formatted=False)\n",
        "\n",
        "    for topico_num, topico in topicos:\n",
        "        palavras, pesos = zip(*topico)\n",
        "        fig = create_figure()\n",
        "        plt.barh(palavras, pesos, color='cyan')  # Cor consistente\n",
        "        plt.title(f'Tópico {topico_num}')\n",
        "        plt.xlabel('Peso')\n",
        "        plt.ylabel('Palavras')\n",
        "        plt.gca().invert_yaxis()\n",
        "        save_fig(fig, f'topico_{topico_num}.png')\n",
        "\n",
        "\n",
        "def analisar_correlacoes(df, colunas_numericas):\n",
        "    \"\"\"\n",
        "    Analisa correlações entre colunas numéricas.\n",
        "    \"\"\"\n",
        "    print(\"Analisando correlações...\")\n",
        "    if len(colunas_numericas) < 2:\n",
        "        print(\"Não há colunas numéricas suficientes.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        correlacao = df[colunas_numericas].corr()\n",
        "        print(\"\\nMatriz de Correlação:\\n\", correlacao)\n",
        "\n",
        "        fig = create_figure()\n",
        "        sns.heatmap(correlacao, annot=True, cmap=DEFAULT_PALETTE, fmt=\".2f\",\n",
        "                    cbar_kws={'label': 'Correlação'})  # Adiciona legenda\n",
        "        plt.title('Matriz de Correlação')\n",
        "        save_fig(fig, 'matriz_correlacao.png')\n",
        "        return correlacao\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na análise de correlação: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- Fluxo Principal (Main) ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    display(Markdown(\"# Análise das Representações da IA no Cinema\"))\n",
        "\n",
        "    # 1. Carregar os dados\n",
        "    df = carregar_dados(url_dataset)\n",
        "    if df is None:\n",
        "        exit()\n",
        "\n",
        "    # 2. Pré-processar os dados\n",
        "    df = pre_processar_dados(df)\n",
        "\n",
        "    # 3. Mostrar informações básicas\n",
        "    display(Markdown(\"## Dados Carregados\"))\n",
        "    print(df.head())\n",
        "    print(df.info())\n",
        "    print(df.describe())\n",
        "\n",
        "    # 4. Análise de Sentimento\n",
        "    colunas_texto = df.select_dtypes(include='object').columns\n",
        "    if len(colunas_texto) > 0:\n",
        "        df = analisar_sentimento(df, colunas_texto[0])\n",
        "        visualizar_distribuicao_sentimento(df)\n",
        "    else:\n",
        "        print(\"Nenhuma coluna de texto encontrada para análise de sentimento.\")\n",
        "\n",
        "    # 5. Modelagem de Tópicos\n",
        "    if len(colunas_texto) > 0:\n",
        "        lda_model, corpus = modelagem_de_topicos(df, colunas_texto[0])\n",
        "        if lda_model is not None:\n",
        "            visualizar_topicos(lda_model, corpus)\n",
        "    else:\n",
        "        print(\"Nenhuma coluna de texto encontrada para modelagem de tópicos.\")\n",
        "\n",
        "    # 6. Análise de Correlações\n",
        "    colunas_numericas = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    analisar_correlacoes(df, colunas_numericas)\n",
        "\n",
        "    display(Markdown(\"## Conclusões Preliminares\"))\n",
        "    display(Markdown(\"Este notebook realizou análises iniciais. Próximas etapas: refinamento do pré-processamento, análise de outras colunas, implementação da análise visual, e integração com outras técnicas (Scikit-learn, XGBoost, SHAP, etc.).\"))"
      ]
    }
  ]
}